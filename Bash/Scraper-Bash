#!/bin/bash
#4chon image downloader
#download pics from thread, reqs curl
#ONLY timer options wurks, needs rewriting of code
verbose=true
output="./"
timer=10


function Quittan() {
   printf "\rInterupted, ${#downloaded[*]} pics downloaded in total from $url"
   echo
   exit 0
}

function Log() {
if $verbose;then
    echo $@
else
    return 1
fi
}

function Usage() {
      echo "Usage: Scraper-Bash [OPTION] <thread url>"
      echo "Default OPTIONS: --output ./ --refresh 10"
      echo "Bash script to scrape 4chan, part of 4chantoolbox."
      echo ""
      echo "  -o/--output           set output dir"
      echo "  -q/--quiet            go silent"
      echo "  -i/--interval N       thread refresh timer"
      echo "  -h/--help	            this message"
      echo ""
      echo "insert <witty comment> here"
}

Check_args() {

if [ -z "$1" ]; then

    Usage
    exit 1
fi

while getopts ":ho:qr" OPTION; do
    case $OPTION in
    h)
        Usage
        exit 1
    ;;
    o)
        if [ -d $OPTARG ]; then
            output=$OPTARG
            shift $((OPTIND-1)); OPTIND=1
        else
            echo "Given output location $OPTARG is not a valid directory. EXITING!"
            #Usage
            exit 1
        fi
    ;;
    q)
        verbose=false
        shift $((OPTIND-1)); OPTIND=1
    ;;
    r)
        timer=$OPTARG
        shift $((OPTIND-1)); OPTIND=1
    ;;
    \?)
        Usage
        exit 0
    ;;
  esac
done

if [ -z "$1" ]; then
    Usage
    exit 1
else
    url="$1"
fi
}

trap "Quittan $1" INT TERM
Check_args $@
Log "Downloading $url"
Log "Saving to location $output"
Log "Timer set to every $timer seconds."

while (true); do

   #printf "\rUpdating...          / $last new pics / $total pics total / $1"

   urls=$( curl -s "$url" | egrep -o 'http://(images|img|cgi).4chan.org/[a-z0-9]+/src/[0-9]*\.(jpg|png|gif)' | sed 'n;d;' )
   Log "Page $url downloaded. Processing images."

   [[ -z $urls ]] && printf "\rThread 404 or fail crap, ${#downloaded[*]} pics downloaded in total from $1" && echo && exit 0
   urlist=( $urls )
   index=0
   for u in ${urlist[@]}; do
        imagename="${u##*/}"
      for i in ${downloaded[@]}; do
         if [[ $u == $i ]]; then
            Log "File $output$imagename exists. Skipping."
            continue 2
         fi
      done
        Log "Getting $imagename"
      { curl -s "$u" > $output$imagename && downloaded+=("$u"); } || { echo "Failed to download $u" && exit 1; }
      let index++
   done
    secs=$timer
    Log "Updating in $timer secs / $index new pics / ${#downloaded[*]} pics total / $url"
    while [ $secs -ge 0 ]; do
      sleep 1 &

      secs=$(( $secs - 1 ))
      wait
    done

done
